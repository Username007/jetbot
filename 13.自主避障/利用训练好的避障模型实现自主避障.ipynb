{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"../图片数据/logo.png\" alt=\"Header\" style=\"width: 800px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@Copyright (C): 2010-2019, Shenzhen Yahboom Tech  \n",
    "@Author: Malloy.Yuan  \n",
    "@Date: 2019-07-17 10:10:02  \n",
    "@LastEditors: Malloy.Yuan  \n",
    "@LastEditTime: 2019-09-17 17:54:19  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载训练模型\n",
    "我们通过运行'训练模型'把'采集数据'代码采集到的数据训练成了我们需要得到的避障模型之后,我们现在开始一步一步使用这个模型,实现避障的功能\n",
    "\n",
    "执行以下代码，初始化PyTorch模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "model = torchvision.models.alexnet(pretrained=False)\n",
    "model.classifier[6] = torch.nn.Linear(model.classifier[6].in_features, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，加载您上传的，已经被训练过的``best_model.pth`` 的模型 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('../collision_avoidance/best_model.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "目前，模型权重计算位于CPU内存上，我们将模型通过我们前面课程跟大家介绍或的'CUDA'转移到GPU上执行,执行下面的代码以使用到GPU。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 预处理功能\n",
    "现在我们加载了模型，但有一个小问题，就是我们的摄像头的图像格式要与训练模型时的图像格式完全相同。要做到这一点，我们需要做一些预处理。分如下几个步骤：\n",
    "\n",
    "1. 从BGR转换为RGB模式\n",
    "2. 从HWC布局转换为CHW布局\n",
    "3. 使用与训练期间相同的参数进行标准化（我们的摄像机提供[0,255]范围内的值，并在[0,1]范围内训练加载的图像，因此我们需要缩放255.0\n",
    "4. 将数据从CPU内存传输到GPU内存\n",
    "5. 批量添加维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "mean = 255.0 * np.array([0.485, 0.456, 0.406])\n",
    "stdev = 255.0 * np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "normalize = torchvision.transforms.Normalize(mean, stdev)\n",
    "\n",
    "def preprocess(camera_value):\n",
    "    global device, normalize\n",
    "    x = camera_value\n",
    "    x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n",
    "    x = x.transpose((2, 0, 1))\n",
    "    x = torch.from_numpy(x).float()\n",
    "    x = normalize(x)\n",
    "    x = x.to(device)\n",
    "    x = x[None, ...]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们现在定义了我们的预处理功能，可以将图像从相机格式转换为神经网络输入的格式。\n",
    "\n",
    "现在，让我们显示我们的摄像头。 你现在应该对此非常熟悉。 我们还将创建一个滑块，用于显示机器人被阻挡的概率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a6c0a9ef4284d969f029888a8fc10ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00C…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import traitlets\n",
    "from IPython.display import display\n",
    "import ipywidgets.widgets as widgets\n",
    "from jetbot import Camera, bgr8_to_jpeg\n",
    "\n",
    "camera = Camera.instance(width=224, height=224)\n",
    "#camera = Camera.instance(width=224, height=224, fps=10)\n",
    "image = widgets.Image(format='jpeg', width=224, height=224)\n",
    "blocked_slider = widgets.FloatSlider(description='blocked', min=0.0, max=1.0, orientation='vertical')\n",
    "\n",
    "camera_link = traitlets.dlink((camera, 'value'), (image, 'value'), transform=bgr8_to_jpeg)\n",
    "\n",
    "display(widgets.HBox([image, blocked_slider]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建驱动电机的robot实例."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetbot import Robot\n",
    "\n",
    "robot = Robot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们创建一个函数，只要相机的值发生变化，就会调用该函数。 此功能将执行以下步骤\n",
    "\n",
    "1. 预处理相机图像\n",
    "2. 执行神经网络\n",
    "3. 当神经网络输出表明我们被阻挡时，我们将向左转，否则我们继续前进。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import time\n",
    "\n",
    "def update(change):\n",
    "    global blocked_slider, robot\n",
    "    x = change['new'] \n",
    "    x = preprocess(x)\n",
    "    y = model(x)\n",
    "    \n",
    "    # we apply the `softmax` function to normalize the output vector so it sums to 1 (which makes it a probability distribution)\n",
    "    y = F.softmax(y, dim=1)\n",
    "    \n",
    "    prob_blocked = float(y.flatten()[0])\n",
    "    \n",
    "    blocked_slider.value = prob_blocked\n",
    "    \n",
    "    if prob_blocked < 0.7:\n",
    "        robot.forward(0.8)\n",
    "    else:\n",
    "        robot.left(0.7)\n",
    "#     if prob_blocked < 0.6:\n",
    "# #       robot.stop()\n",
    "#          robot.forward(0.7)\n",
    "#     else:\n",
    "# #       robot.stop()\n",
    "#          robot.left(0.7)\n",
    "    \n",
    "    #time.sleep(0.001)\n",
    "        \n",
    "update({'new': camera.value})  # we call the function once to intialize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们已经创建了神经网络执行功能，但现在我们需要将它附加到相机进行处理。\n",
    "\n",
    "我们用``observe`` 函数完成这个处理。\n",
    "\n",
    "提示：此代码将开始移动机器人！ 请确保你的Jetbot位于可移动地带,避免跌落损坏!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.observe(update, names='value')  # this attaches the 'update' function to the 'value' traitlet of our camera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行完上面单元格代码块后，Jetbot就开始为每个检测到的照片生成新命令。 首先将机器人放在地上，看看它遇到障碍物时的反应。\n",
    "\n",
    "如果要停止此行为，可以通过执行以下代码来取消。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.unobserve(update, names='value')\n",
    "time.sleep(1)\n",
    "robot.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "也许你希望Jetbot在没有流式传输视频的情况下运行，这样会减少JetBot的运算负担。 执行如下代码，你可以取消摄像头的连接。\n",
    "只是不推流到浏览器上，但在Jetbot上摄像头仍然是工作状态中的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_link.unlink()  # don't stream to browser (will still run camera)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "又如果要继续在浏览器显示视频，请执行以下代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_link.link()  # stream to browser (wont run camera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
