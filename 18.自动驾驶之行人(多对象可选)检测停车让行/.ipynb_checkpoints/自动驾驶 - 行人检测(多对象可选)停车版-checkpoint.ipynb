{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"../图片数据/logo.png\" alt=\"Header\" style=\"width: 800px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@Copyright (C): 2010-2019, Shenzhen Yahboom Tech  \n",
    "@Author: Malloy.Yuan  \n",
    "@Date: 2019-07-17 10:10:02  \n",
    "@LastEditors: Malloy.Yuan  \n",
    "@LastEditTime: 2019-09-17 17:54:19  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自动驾驶 - 行人检测(多对象可选)停车让行版\n",
    "\n",
    "在这个示例中中，我们将使用我们训练过的模型使jetBot在轨道上平稳移动。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载模型\n",
    "\n",
    "我们假设您已经按照自动驾驶训练模型示例中的指示训练好了``best_steering_model_xy.pth``到该示例文件夹下\n",
    "\n",
    "> ### 执行下面我们看似应该很熟悉的代码来初始化PyTorch模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "\n",
    "model = torchvision.models.resnet18(pretrained=False)\n",
    "model.fc = torch.nn.Linear(512, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from servoserial import ServoSerial\n",
    "import threading\n",
    "# 杀掉线程\n",
    "import inspect\n",
    "import ctypes\n",
    "import ipywidgets.widgets as widgets\n",
    "from IPython.display import display\n",
    "import time\n",
    "\n",
    "controller = widgets.Controller(index=0)\n",
    "display(controller)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 从对象跟随的示例中移植对象检测功能到此实例函数中进行演示\n",
    "\n",
    "加载对象检测模型\n",
    "\n",
    "添加相关算法方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetbot import ObjectDetector\n",
    "global object_model\n",
    "object_model = ObjectDetector('ssd_mobilenet_v2_coco.engine')\n",
    "\n",
    "def detection_center(detection):\n",
    "    \"\"\"计算对象的中心x、y坐标\"\"\"\n",
    "    bbox = detection['bbox']\n",
    "    center_x = (bbox[0] + bbox[2]) / 2.0 - 0.5\n",
    "    center_y = (bbox[1] + bbox[3]) / 2.0 - 0.5\n",
    "    return (center_x, center_y)\n",
    "\n",
    "def norm(vec):\n",
    "    \"\"\"计算二维向量的长度\"\"\"\n",
    "    return np.sqrt(vec[0]**2 + vec[1]**2)\n",
    "\n",
    "def closest_detection(detections):\n",
    "    \"\"\"查找最接近图像中心的检测\"\"\"\n",
    "    #先清除缓存\n",
    "    closest_detection = None\n",
    "    for det in detections:\n",
    "        center = detection_center(det)\n",
    "        if closest_detection is None:\n",
    "            closest_detection = det\n",
    "        elif norm(detection_center(det)) < norm(detection_center(closest_detection)):\n",
    "            closest_detection = det\n",
    "    return closest_detection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，从您上载的 ``best_steering_model_xy.pth`` 文件中加载经过训练的模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('best_steering_model_xy.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因为模型权重位于CPU内存上，然后还是一如既往的执行下面的代码传输到GPU设备。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "model = model.to(device)\n",
    "model = model.eval().half()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建预处理函数\n",
    "\n",
    "我们现在已经加载了我们的模型，但是有一个小问题。我们训练模型的格式与相机的格式并不完全匹配。\n",
    "要做到这一点，我们需要做一些预处理。这包括以下步骤:\n",
    "\n",
    "1. 从HWC布局转换为CHW布局\n",
    "2. 使用与我们在训练期间相同的参数进行标准化(我们的相机在[0,255]范围内提供值，而训练加载的图像在[0,1]范围内，因此我们需要缩放255.0\n",
    "3. 将数据从CPU内存传输到GPU内存\n",
    "4. 添加批处理维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import PIL.Image\n",
    "import numpy as np\n",
    "\n",
    "mean = torch.Tensor([0.485, 0.456, 0.406]).cuda().half()\n",
    "std = torch.Tensor([0.229, 0.224, 0.225]).cuda().half()\n",
    "\n",
    "def preprocess(image):\n",
    "    image = PIL.Image.fromarray(image)\n",
    "    image = transforms.functional.to_tensor(image).to(device).half()\n",
    "    image.sub_(mean[:, None, None]).div_(std[:, None, None])\n",
    "    return image[None, ...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在我们已经定义了预处理函数，它可以将图像从摄像机格式转换为神经网络输入格式。\n",
    "现在，让我们开始展示我们的相机,经历过上几次示例的学习你现在应该很熟悉这个了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "# import ipywidgets\n",
    "import ipywidgets.widgets as widgets\n",
    "import traitlets\n",
    "from jetbot import Camera, bgr8_to_jpeg\n",
    "from servoserial import ServoSerial\n",
    "\n",
    "# camera = Camera()\n",
    "camera = Camera.instance(width=300, height=300)\n",
    "#camera = Camera.instance(width=224, height=224, fps=10)\n",
    "servo_device = ServoSerial() \n",
    "\n",
    "# image_widget = ipywidgets.Image()\n",
    "# traitlets.dlink((camera, 'value'), (image_widget, 'value'), transform=bgr8_to_jpeg)\n",
    "# display(image_widget)\n",
    "\n",
    "image_widget = widgets.Image(format='jpeg', width=300, height=300)\n",
    "display(image_widget)\n",
    "\n",
    "\n",
    "def camservoInitFunction():\n",
    "    global leftrightpulse, updownpulse\n",
    "    leftrightpulse = 2048\n",
    "    updownpulse = 2048\n",
    "    servo_device.Servo_serial_control(1, 2048)\n",
    "    time.sleep(0.1)\n",
    "    servo_device.Servo_serial_control(2, 1300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们将使用下面的代码打印出检测到的对象。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detections = object_model(camera.value)\n",
    "print(detections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后创建机器人实例来驱动电机"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetbot import Robot\n",
    "\n",
    "robot = Robot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在，我们将定义滑块来控制JetBot\n",
    "> ### 提示:我们已经为滑块配置初始化值，这些初始值适用于我们Yahboom官方提供的地图,但是如果你要训练\n",
    "到你自己不同的道路地图上时这些值可能不适用于您的数据集，因此请根据您的设置和环境增加或减少滑块\n",
    "\n",
    "1. 速度控制(speed_gain_slider):要启动JetBot，请增加``speed_gain_slider`` \n",
    "2. 转向增益控制(steering_gain_sloder):如果你看到JetBot正在旋转，你需要减少``steering_gain_slider``，直到它变得平滑\n",
    "3. 转向偏置控制(steering_bias_slider):如果您看到JetBot偏向赛道的极右或极左，您应该控制这个滑块，直到JetBot开始跟踪位于中心的直线或赛道。这就解释了运动偏差和相机偏移\n",
    "\n",
    ">  ## 注意:在你滑动上面所提到的相关滑块时,为获得平滑的JetBot道路跟随行为不应大幅度快速的移动滑块值,应平缓移动滑块值调节运动参数."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets\n",
    "speed_gain_slider = ipywidgets.FloatSlider(min=0.0, max=1.0, step=0.01, value=0.51,description='speed gain')\n",
    "steering_gain_slider = ipywidgets.FloatSlider(min=0.0, max=1.0, step=0.01, value=0.21, description='steering gain')\n",
    "steering_dgain_slider = ipywidgets.FloatSlider(min=0.0, max=0.5, step=0.001, value=0.24, description='steering kd')\n",
    "steering_bias_slider = ipywidgets.FloatSlider(min=-0.3, max=0.3, step=0.01, value=0, description='steering bias')\n",
    "\n",
    "display(speed_gain_slider, steering_gain_slider, steering_dgain_slider, steering_bias_slider)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(基础速度))speed_gain_slider     -> 0.51(外弯道)   0.60(内弯道)    0.42    0.56\n",
    "\n",
    "(P)steering_gain_slider          -> 0.25           0.37            0.22    0.27\n",
    "\n",
    "(D)steering_dgain_slider         -> 0.24           0.24            0.10    0.13\n",
    "\n",
    "(基础转向值)steering_bias_slider -> 0.00           0.00            0.00    0.00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，让我们展示一些滑块，让我们看看JetBot在想什么。\n",
    "\n",
    "x和y滑块将显示预测的x、y值。\n",
    "\n",
    "转向滑块将显示我们估计的转向值。请记住，这个值不是目标的实际角度，而是一个几乎成比例的值。当实际角度为``0``时，这个为0，它会随着实际角度的增大/减小而增大/减小。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_slider = ipywidgets.FloatSlider(min=-1.0, max=1.0, description='x')\n",
    "y_slider = ipywidgets.FloatSlider(min=0, max=1.0, orientation='vertical', description='y')\n",
    "steering_slider = ipywidgets.FloatSlider(min=-1.0, max=1.0, description='steering')\n",
    "speed_slider = ipywidgets.FloatSlider(min=0, max=1.0, orientation='vertical', description='speed')\n",
    "\n",
    "display(ipywidgets.HBox([y_slider, speed_slider]))\n",
    "display(x_slider, steering_slider)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们将创建一个函数，该函数将在摄像机的值发生更改时被调用。这个函数将执行以下步骤\n",
    "\n",
    "1. 预处理相机图像\n",
    "2. 执行神经网络\n",
    "3. 计算近似转向值\n",
    "4. 使用 比例/微分控制(PD) 控制电机"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angle = 0.0\n",
    "angle_last = 0.0\n",
    "\n",
    "def execute(change):\n",
    "    global angle, angle_last\n",
    "    image = change['new']\n",
    "    \n",
    "    # 计算出所有检测到的对象\n",
    "    detections = object_model(image)\n",
    "    \n",
    "    # 在图像上绘制所有检测\n",
    "    for det in detections[0]:\n",
    "        bbox = det['bbox']\n",
    "        cv2.rectangle(image, (int(300 * bbox[0]), int(300 * bbox[1])), (int(300 * bbox[2]), int(300 * bbox[3])), (255, 0, 0), 2)\n",
    "    \n",
    "    #选择你所要跟踪的对象,即选择label_widget的值,1是person,人\n",
    "    # select detections that match selected class label\n",
    "    matching_detections = [d for d in detections[0] if d['label'] == 1]\n",
    "    \n",
    "    #然后再把要跟踪的对象用绿色的线条标注出\n",
    "    # get detection closest to center of field of view and draw it\n",
    "    det = closest_detection(matching_detections)\n",
    "    if det is not None:\n",
    "        bbox = det['bbox']\n",
    "        cv2.rectangle(image, (int(300 * bbox[0]), int(300 * bbox[1])), (int(300 * bbox[2]), int(300 * bbox[3])), (0, 255, 0), 4)\n",
    "        ''' 如果检测到道路上需要避让的对象,就停止当前Jetbot的运动 '''\n",
    "        robot.stop()\n",
    "    else:\n",
    "        xy = model(preprocess(image)).detach().float().cpu().numpy().flatten()\n",
    "        x = xy[0]\n",
    "        y = (0.5 - xy[1]) / 2.0\n",
    "\n",
    "        x_slider.value = x\n",
    "        y_slider.value = y\n",
    "\n",
    "        speed_slider.value = speed_gain_slider.value\n",
    "\n",
    "        angle = np.arctan2(x, y)\n",
    "        pid = angle * steering_gain_slider.value + (angle - angle_last) * steering_dgain_slider.value\n",
    "        angle_last = angle\n",
    "\n",
    "        steering_slider.value = pid + steering_bias_slider.value\n",
    "\n",
    "        #PID+基础速度+增益\n",
    "        robot.left_motor.value = max(min(speed_slider.value + steering_slider.value, 1.0), 0.0)\n",
    "        robot.right_motor.value = max(min(speed_slider.value - steering_slider.value, 1.0), 0.0)\n",
    "    \n",
    "    \n",
    "    # update image widget\n",
    "    image_widget.value = bgr8_to_jpeg(image)\n",
    "execute({'new': camera.value})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们已经创建了我们的神经网络执行函数，但是现在我们需要将它附加到摄像机上进行处理。\n",
    "> ## 注意注意:以下函数由于之前通过画面变化来调用检测函数延迟比较大， 现在暂时采用循环不断调用检测函数提高画面流畅度，以及提高识别效果，由于在主线程中不断循环检测会导致卡死在这里并且使得jupyterlab的所有按键失灵，所以采用将不断检测的死循环放到一个子线程1里面\n",
    "\n",
    "> ## 提示:此代码将移动机器人!!请把Jetbot机器人放置在你之前训练过的地图上,如果你采集的数据和模型训练得够好的话,你讲看到Jetbot平稳的运行在道路上!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#camservoInitFunction()\n",
    "#camera.observe(execute, names='value')\n",
    "\n",
    "import threading\n",
    "import inspect\n",
    "import ctypes\n",
    "'''以下为定义关闭线程函数'''\n",
    "def _async_raise(tid, exctype):\n",
    "  \"\"\"raises the exception, performs cleanup if needed\"\"\"\n",
    "  tid = ctypes.c_long(tid)\n",
    "  if not inspect.isclass(exctype):\n",
    "    exctype = type(exctype)\n",
    "  res = ctypes.pythonapi.PyThreadState_SetAsyncExc(tid, ctypes.py_object(exctype))\n",
    "  if res == 0:\n",
    "    raise ValueError(\"invalid thread id\")\n",
    "  elif res != 1:\n",
    "    # \"\"\"if it returns a number greater than one, you're in trouble,\n",
    "    # and you should call it again with exc=NULL to revert the effect\"\"\"\n",
    "    ctypes.pythonapi.PyThreadState_SetAsyncExc(tid, None)\n",
    "    raise SystemError(\"PyThreadState_SetAsyncExc failed\")\n",
    "def stop_thread(thread):\n",
    "  _async_raise(thread.ident, SystemExit)\n",
    "'''线程1的函数，里面不断调用检测函数'''\n",
    "def test():\n",
    "    while True:\n",
    "        execute({'new': camera.value})        \n",
    "\n",
    "        \n",
    "thread1 = threading.Thread(target=test)\n",
    "thread1.setDaemon(False)\n",
    "thread1.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果你的Jetbot各项功能正常,它现在应该会为每一个新的相机帧生成新的命令。\n",
    "现在，您可以将JetBot放置在已收集数据的轨道上，并查看它是否可以跟踪轨道。\n",
    "如果希望停止此行为，可以通过执行下面单元格的代码卸载此回调函数的绑定。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_thread(thread1)\n",
    "camera.unobserve(execute, names='value')\n",
    "time.sleep(0.1)\n",
    "robot.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robot.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jetbot_motion():\n",
    "    count1 = count2 = count3 = count4 =  count5 = 0\n",
    "    while 1:\n",
    "        #小车左右DC motor\n",
    "        if controller.axes[1].value <= 0.1:\n",
    "            if (controller.axes[0].value <= 0.1 and controller.axes[0].value >= -0.1 \n",
    "                and controller.axes[1].value <= 0.1 and controller.axes[1].value >= -0.1):\n",
    "                robot.stop()\n",
    "            else:\n",
    "                robot.set_motors(-controller.axes[1].value + controller.axes[0].value, -controller.axes[1].value - controller.axes[0].value)\n",
    "            \n",
    "            time.sleep(0.01)\n",
    "        else:\n",
    "            robot.set_motors(-controller.axes[1].value - controller.axes[0].value, -controller.axes[1].value + controller.axes[0].value)\n",
    "            time.sleep(0.01)\n",
    "          #手柄操作代码---2(Xbox360手柄)\n",
    "#         if controller.axes[1].value <= 0:\n",
    "#             robot.set_motors(-controller.axes[1].value + controller.axes[0].value, -controller.axes[1].value - controller.axes[0].value)\n",
    "#             time.sleep(0.01)\n",
    "#         else:\n",
    "#             robot.set_motors(-controller.axes[1].value - controller.axes[0].value, -controller.axes[1].value + controller.axes[0].value)\n",
    "#             time.sleep(0.01)\n",
    "            \n",
    "# thread1 = threading.Thread(target=jetbot_motion)\n",
    "# thread1.setDaemon(False)\n",
    "# thread1.start()\n",
    "\n",
    "def _async_raise(tid, exctype):\n",
    "    \"\"\"raises the exception, performs cleanup if needed\"\"\"\n",
    "    tid = ctypes.c_long(tid)\n",
    "    if not inspect.isclass(exctype):\n",
    "        exctype = type(exctype)\n",
    "    res = ctypes.pythonapi.PyThreadState_SetAsyncExc(tid, ctypes.py_object(exctype))\n",
    "    if res == 0:\n",
    "        raise ValueError(\"invalid thread id\") \n",
    "    elif res != 1:\n",
    "        # \"\"\"if it returns a number greater than one, you're in trouble,\n",
    "        # and you should call it again with exc=NULL to revert the effect\"\"\"\n",
    "        ctypes.pythonapi.PyThreadState_SetAsyncExc(tid, None)\n",
    "        \n",
    "def stop_thread(thread):\n",
    "    _async_raise(thread.ident, SystemExit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread1 = threading.Thread(target=jetbot_motion)\n",
    "thread1.setDaemon(False)\n",
    "thread1.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_thread(thread1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 总结\n",
    "如果你的JetBot没有很好地跟踪道路，试着找出它失败的地方。其美妙之处在于，我们可以为这些发生故障场景收集更多的数据，JetBot应该会做得更好"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
